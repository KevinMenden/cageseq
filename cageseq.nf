#!/usr/bin/env nextflow
/*
========================================================================================
                                    nf-core/cageseq
========================================================================================
nf-core/cageseq Analysis Pipeline.
#### Homepage / Documentation
https://github.com/nf-core/cageseq
----------------------------------------------------------------------------------------
*/

def helpMessage() {

    log.info nfcoreHeader()
    log.info"""

    Usage:

    The typical command for running the pipeline is as follows:

    nextflow run nf-core/cageseq --input '*_R1.fastq.gz' -profile docker

    Mandatory arguments:
        --input [file]                    Path to input data (must be surrounded with quotes)
        -profile [str]                    Configuration profile to use. Can use multiple (comma separated)
                                            Available: docker, singularity, conda, test, awsbatch, <institute> and more

    Trimming:
        --save_trimmed [bool]             Set to true to Save trimmed FastQ files
        --trim_ecop [bool]                Set to false to not trim the EcoP site
        --trim_linker [bool]              Set to false to not trim the linker
        --trim_5g [bool]                  Set to false to not trim the additonal G at the 5' end
        --trim_artifacts [bool]           Set to false to not trim artifacts
        --artifacts_5end [file]           Path to 5 end artifact file, if not given the pipeline will use a default file with all possible artifacts
        --artifacts_3end [file]           Path to 3 end artifact file, if not given the pipeline will use a default file with all possible artifacts

    References                            If not specified in the configuration file or you wish to overwrite any of the references
        --fasta [file]                    Path to fasta reference
        --genome [str]                    Name of iGenomes reference
        --gtf [file]                      Path to gtf file, used to generate the STAR index, for STAR alignment and for the clustering QC

    Ribosomal RNA removal:
        --remove_ribo_rna [bool]          Removes ribosomal RNA using SortMeRNA
        --save_non_ribo_reads [bool]      Save FastQ file intermediates after removing rRNA
        --ribo_database_manifest [string] Path to file that contains file paths for rRNA databases, optional

    Alignment:
        --aligner [str]                   Specifies the aligner to use (available are: 'star', 'bowtie1')
        --star_index [file]               Path to STAR index, set to false if igenomes should be used
        --bowtie_index [file]             Path to bowtie index, set to false if igenomes should be used

    Clustering:
        --min_cluster [int]               Minimum amount of reads to build a cluster with paraclu. Default ${params.min_cluster}
        --tpm_cluster_threshold [int]     --tpm_cluster_threshold [int] Threshold for expression count of ctss considered in paraclu clustering. Default: ${params.tpm_cluster_threshold}

    Output:
        --bigwig [bool]                    Set this option to get ctss files in bigwig-format, in addition to the default in bed-format

    Skipping options:
        --skip_initial_fastqc [bool]      Skip FastQC run on input reads
        --skip_trimming [bool]            Skip all trimming steps
        --skip_trimming_fastqc [bool]     Skip FastQC run on trimmed reads
        --skip_alignment [bool]           Skip alignment step
        --skip_samtools_stats [bool]      Skip samtools stats QC step of aligned reads
        --skip_ctss_generation [bool]     Skip steps generating CTSS files including clustering, bed/bigwig and count table output generation
        --skip_ctss_qc [bool]             Skip running RSeQC's read distribution QC step on the clustered CTSS

    Other options:
        --outdir [file]                   The output directory where the results will be saved
        --publish_dir_mode [str]          Mode for publishing results in the output directory. Available: symlink, rellink, link, copy, copyNoFollow, move (Default: copy)
        --email [email]                   Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits
        --email_on_fail [email]           Same as --email, except only send mail if the workflow is not successful
        --max_multiqc_email_size [str]    Threshold size for MultiQC report to be attached in notification email. If file generated by pipeline exceeds the threshold, it will not be attached (Default: 25MB)
        -name [str]                       Name for the pipeline run. If not specified, Nextflow will automatically generate a random mnemonic

    AWSBatch options:
        --awsqueue [str]                  The AWSBatch JobQueue that needs to be set when running on AWSBatch
        --awsregion [str]                 The AWS Region for your AWS Batch job to run on
        --awscli [str]                    Path to the AWS CLI tool
    """.stripIndent()
}

// Show help message
if (params.help) {
    helpMessage()
    exit 0
}

/*
 * SET UP CONFIGURATION VARIABLES
 */

// Check if genome exists in the config file
if (params.genomes && params.genome && !params.genomes.containsKey(params.genome)) {
    exit 1, "The provided genome '${params.genome}' is not available in the iGenomes file. Currently the available genomes are ${params.genomes.keySet().join(", ")}"
}

params.star_index = params.genome ? params.genomes[ params.genome ].star ?: false : false
params.bowtie_index = params.genome ? params.genomes[ params.genome ].bowtie1 ?: false : false
params.fasta = params.genome ? params.genomes[ params.genome ].fasta ?: false : false
params.gtf = params.genome ? params.genomes[ params.genome ].gtf ?: false : false

// Get rRNA databases
// Default is set to bundled DB list in `assets/rrna-db-defaults.txt`

ribo_database = file(params.ribo_database_manifest)
if (ribo_database.isEmpty()) {exit 1, "File ${ribo_database.getName()} is empty!"}
Channel
    .from( ribo_database.readLines() )
    .map { row -> file(row) }
    .set { fasta_sortmerna }

//////////////////////
// Validate inputs
//////////////////////

// Check input path parameters to see if they exist
checkPathParamList = [
    params.input, params.gtf, params.fasta,
    params.star_index
]




if (params.aligner != 'star' && params.aligner != 'bowtie1') {
    exit 1, "Invalid aligner option: ${params.aligner}. Valid options: 'star', 'bowtie1'"
}
if( params.star_index && params.aligner == 'star' ){
    star_index = Channel
        .fromPath(params.star_index, checkIfExists: true)
        .ifEmpty { exit 1, "STAR index not found: ${params.star_index}" }
}
else if( params.bowtie_index && params.aligner == 'bowtie1' ){
    bowtie_index = Channel
        .fromPath(params.bowtie_index, checkIfExists: true)
        .ifEmpty { exit 1, "bowtie index not found: ${params.bowtie_index}" }
}
else if ( params.fasta ){
    Channel
        .fromPath(params.fasta, checkIfExists: true)
        .ifEmpty { exit 1, "fasta file not found: ${params.fasta}" }
        .into { fasta_star_index; fasta_bowtie_index}
}
else {
    exit 1, "No reference genome specified!"
}


if( params.fasta ){
Channel
    .fromPath(params.fasta, checkIfExists: true)
    .ifEmpty { exit 1, "fasta file not found: ${params.fasta}" }
    .set{fasta_rseqc}
} else {
    exit 1, "No fasta file specified!"
}

if( params.gtf ){
    Channel
        .fromPath(params.gtf, checkIfExists: true)
        .ifEmpty { exit 1, "GTF annotation file not found: ${params.gtf}" }
        .into { gtf_make_STAR_index; gtf_star; gtf_rseqc}
} else {
    exit 1, "No GTF annotation specified! Needed for STAR and clustering QC."
}

if( params.artifacts_5end ){
    ch_5end_artifacts = Channel
        .fromPath(params.artifacts_5end)
}
else {
    ch_5end_artifacts = Channel
        .fromPath("$baseDir/assets/artifacts_5end.fasta")
}

if( params.artifacts_3end ){
    ch_3end_artifacts = Channel
        .fromPath(params.artifacts_3end)
}
else {
    ch_3end_artifacts = Channel
        .fromPath("$baseDir/assets/artifacts_3end.fasta")
}



// Has the run name been specified by the user?
// this has the bonus effect of catching both -name and --name
custom_runName = params.name
if (!(workflow.runName ==~ /[a-z]+_[a-z]+/)) {
    custom_runName = workflow.runName
}

// Check AWS batch settings
if (workflow.profile.contains('awsbatch')) {
    // AWSBatch sanity checking
    if (!params.awsqueue || !params.awsregion) exit 1, "Specify correct --awsqueue and --awsregion parameters on AWSBatch!"
    // Check outdir paths to be S3 buckets if running on AWSBatch
    // related: https://github.com/nextflow-io/nextflow/issues/813
    if (!params.outdir.startsWith('s3:')) exit 1, "Outdir not on S3 - specify S3 Bucket to run on AWSBatch!"
    // Prevent trace files to be stored on S3 since S3 does not support rolling files.
    if (params.tracedir.startsWith('s3:')) exit 1, "Specify a local tracedir or run without trace! S3 cannot be used for tracefiles."
}


// Stage config files
ch_multiqc_config = file("$baseDir/assets/multiqc_config.yaml", checkIfExists: true)
ch_multiqc_custom_config = params.multiqc_config ? Channel.fromPath(params.multiqc_config, checkIfExists: true) : Channel.empty()
ch_output_docs = file("$baseDir/docs/output.md", checkIfExists: true)
ch_output_docs_images = file("$baseDir/docs/images/", checkIfExists: true)

/*
 * Create a channel for input read files
 */
if (params.input_paths) {
Channel
    .from(params.input_paths)
    .map { row -> [ row[0].replaceAll("\\s","_"), file(row[1])] }
    .ifEmpty { exit 1, "params.input was empty - no input files supplied" }
    .into { ch_read_files_fastqc; read_files_trimming }
} else {
Channel
    .fromFilePairs( params.input )
    .ifEmpty { exit 1, "Cannot find any reads matching: ${params.input}\nNB: Path needs to be enclosed in quotes!\nNB: Path requires at least one * wildcard!\n" }
    .into { ch_read_files_fastqc; read_files_trimming }

}

// Header log info
log.info nfcoreHeader()
def summary = [:]
if (workflow.revision){
    summary['Pipeline Release']           = workflow.revision
}
summary['Run Name']                       = custom_runName ?: workflow.runName
summary['Input']                          = params.input
if (params.skip_initial_fastqc)  {
    summary['Skip Initial FastQC']        = 'Yes'
}
if (params.artifacts_5end){
    summary["5' artifacts"]               = params.artifacts_5end
}
if (params.artifacts_3end){
    summary["3' artifacts"]               = params.artifacts_3end
}
if (params.skip_trimming) {
    summary['Skip Trimming']              = 'Yes'
} else {
    summary['trim_ecop']                  = params.trim_ecop
    summary['trim_linker']                = params.trim_linker
    summary['trim_5g']                    = params.trim_5g
    summary['trim_artifacts']             = params.trim_artifacts
    summary['eco_site']                   = params.eco_site
    summary['linker_seq']                 = params.linker_seq
}
summary['Remove rRNA']                    = params.remove_ribo_rna
if (params.skip_trimming_fastqc){
    summary['Skip Trimming FastQC']       = 'Yes'
}
if (params.skip_alignment){
    summary['Skip Alignment']             = 'Yes'
}
else {
    if (params.aligner == 'star') {
        summary['Aligner']                = 'STAR'
        if (params.star_index){
            summary['STAR Index']         = params.star_index
            } else if (params.fasta){
            summary['Fasta Ref']          = params.fasta
        }
    } else if (params.aligner == 'bowtie1') {
        summary['Aligner']                = 'bowtie1'
        if (params.bowtie_index){
            summary['bowtie Index']       = params.bowtie_index
        } else if (params.fasta){
            summary['Fasta Ref']          = params.fasta
        }
    }
}
if(params.skip_ctss_generation){
    summary['Skip CTSS generation']       = 'Yes'
} else{
    summary['Min. cluster']               = params.min_cluster
    summary['Cluster Threshold']          = params.tpm_cluster_threshold
}
if(params.skip_ctss_qc) {
    summary['Skip CTSS QC']               = 'Yes'
}
if(params.bigwig){
    summary['bigwig output']              = 'Yes'
}
summary['Save Reference']                 = params.save_reference
summary['Max Resources']                  = "$params.max_memory memory, $params.max_cpus cpus, $params.max_time time per job"
if (workflow.containerEngine){
    summary['Container']                  = "$workflow.containerEngine - $workflow.container"
}
summary['Output dir']                     = params.outdir
summary['Launch dir']                     = workflow.launchDir
summary['Working dir']                    = workflow.workDir
summary['Script dir']                     = workflow.projectDir
summary['User']                           = workflow.userName
if (workflow.profile.contains('awsbatch')) {
    summary['AWS Region']                 = params.awsregion
    summary['AWS Queue']                  = params.awsqueue
    summary['AWS CLI']                    = params.awscli
}
summary['Config Profile']                 = workflow.profile
if (params.config_profile_description){
    summary['Config Profile Description'] = params.config_profile_description
}
if (params.config_profile_contact){
    summary['Config Profile Contact']     = params.config_profile_contact
}
if (params.config_profile_url){
    summary['Config Profile URL']         = params.config_profile_url
}
summary['Config Files']                   = workflow.configFiles.join(', ')
if (params.email || params.email_on_fail) {
    summary['E-mail Address']             = params.email
    summary['E-mail on failure']          = params.email_on_fail
    summary['MultiQC maxsize']            = params.max_multiqc_email_size
}
log.info summary.collect { k,v -> "${k.padRight(18)}: $v" }.join("\n")
log.info "-\033[2m--------------------------------------------------\033[0m-"

// Check the hostnames against configured profiles
checkHostname()

Channel.from(summary.collect{ [it.key, it.value] })
    .map { k,v -> "<dt>$k</dt><dd><samp>${v ?: '<span style=\"color:#999999;\">N/A</a>'}</samp></dd>" }
    .reduce { a, b -> return [a, b].join("\n            ") }
    .map { x -> """
    id: 'nf-core-cageseq-summary'
    description: " - this information is collected when the pipeline is started."
    section_name: 'nf-core/cageseq Workflow Summary'
    section_href: 'https://github.com/nf-core/cageseq'
    plot_type: 'html'
    data: |
        <dl class=\"dl-horizontal\">
            $x
        </dl>
    """.stripIndent() }
    .set { ch_workflow_summary }

/////////////////////////////
/* Include process modules */
/////////////////////////////

// Define options for modules
def modules = params.modules.clone()

def fastqc_options = modules['fastqc']
def publish_genome_options = params.save_reference ? [publish_dir: 'genome'] : [publish_files: false]
def genome_options = publish_genome_options

// Include the modules
include { FASTQC } from '.modules/nf-core/software/fastqc/main' addParams( options: params.fastqc_options )
include { GET_CHROM_SIZES } from '.modules/local/process/get_chrom_sizes' addParams( options: params.publish_genome_options )
include { GTF2BED } from '.modules/local/process/get_chrom_sizes' addParams( options: params.genome_options )


// Check mandatory parameters
if (params.input) { ch_input = file(params.input) } else { exit 1, 'Input not specified!'}
if (params.fasta) { ch_fasta = file(params.fasta) } else { exit 1, 'Genome fasta file not specified!'}
if (params.gtf) { ch_gtf = file(params.gtf) } else { exit 1, "No GTF annotation specified!"}

///////////////////////
/* CAGE-seq workflow */
///////////////////////

workflow {
    // FASTQC
    FASTQC( ch_input )
    fastqc_html = FASTQC.out.html
    fastqc_zip = FASTQC.out.zip
    fastqc_version = FASTQC.out.version

    // Convert GTF
    ch_gene_bed = GTF2BED( ch_gtf )

    // Get chrom sizes
    GET_CHROM_SIZES( ch_fasta )
    
    // Make star index
    // Make bowtie index

    // Trim adapters
    // --> adapters, artifacts, 5'G
    // remove ribo RNA

    // STAR

    // BOWTIE

    //get CTSS
    // make bigwig
    //cluster ctss
    //egnerate counts
    // generate count matrix
    // ctss qc






    // Get software versions
    ch_software_versions = Channel.empty()
    ch_software_versions = ch_software_versions.mix(FASTQ.out.version.first().ifEmpty(null))
    GET_SOFTWARE_VERSIONS ( ch_software_versions.map { it }.collect())
}
